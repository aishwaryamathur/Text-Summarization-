{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8nAOf_4BHd3Z",
    "outputId": "76eaf9a1-72bd-4483-df7e-92aa408015bb"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import re            \n",
    "from tqdm import tqdm,trange \n",
    "import os  \n",
    "import numpy as np   \n",
    "import pandas as pd  \n",
    "import nltk    \n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# !pip install rouge\n",
    "# !pip install networkx\n",
    "import networkx as nx\n",
    "from rouge import Rouge\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The available article categories are Entertainment, Business, Politics, Sport, Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "_wkTnj9aHmKS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Article Categories - Entertainment, Business, Politics, Sport, Tech\n",
      "Enter the category of articles: Entertainment\n",
      "Entertainment\n",
      "\"Reading the Entertainment data\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 386/386 [00:20<00:00, 18.80it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Article Categories - Entertainment, Business, Politics, Sport, Tech\")\n",
    "type_of_article = input(\"Enter the category of articles: \") #entertainment/business/politices/sport/tech\n",
    "print(type_of_article)\n",
    "root_path = r\"C:\\Users\\HP PAV -15 AU111TX\\Desktop\\NLP\\Project\\archive (1)\\BBC News Summary\\BBC News Summary\"\n",
    "num_of_article = len(os.listdir(f\"{root_path}/News Articles/{type_of_article}\"))\n",
    "print(f'\"Reading the {type_of_article} data\"')\n",
    "df = pd.DataFrame(columns=['title','article','summary'])\n",
    "\n",
    "for i in tqdm(range(num_of_article)):\n",
    "    with open(f'{root_path}/News Articles/{type_of_article}/{(i+1):03d}.txt', 'r') as f:\n",
    "        article = f.read().splitlines()\n",
    "    with open(f'{root_path}/Summaries/{type_of_article}/{(i+1):03d}.txt', 'r') as f:\n",
    "        summary = f.read().splitlines()\n",
    "    df.loc[i] = [article[0],article[2:],summary[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gallery unveils interactive tree</td>\n",
       "      <td>[A Christmas tree that can receive text messag...</td>\n",
       "      <td>The messages will be \"unwrapped\" by sculptor R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jarre joins fairytale celebration</td>\n",
       "      <td>[French musician Jean-Michel Jarre is to perfo...</td>\n",
       "      <td>Bloom is to be formally presented with the Han...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Musical treatment for Capra film</td>\n",
       "      <td>[The classic film It's A Wonderful Life is to ...</td>\n",
       "      <td>The classic film It's A Wonderful Life is to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Richard and Judy choose top books</td>\n",
       "      <td>[The 10 authors shortlisted for a Richard and ...</td>\n",
       "      <td>\"It was very hard to follow last year's extrem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Poppins musical gets flying start</td>\n",
       "      <td>[The stage adaptation of children's film Mary ...</td>\n",
       "      <td>Mary Poppins was originally created by author ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               title  \\\n",
       "0   Gallery unveils interactive tree   \n",
       "1  Jarre joins fairytale celebration   \n",
       "2   Musical treatment for Capra film   \n",
       "3  Richard and Judy choose top books   \n",
       "4  Poppins musical gets flying start   \n",
       "\n",
       "                                             article  \\\n",
       "0  [A Christmas tree that can receive text messag...   \n",
       "1  [French musician Jean-Michel Jarre is to perfo...   \n",
       "2  [The classic film It's A Wonderful Life is to ...   \n",
       "3  [The 10 authors shortlisted for a Richard and ...   \n",
       "4  [The stage adaptation of children's film Mary ...   \n",
       "\n",
       "                                             summary  \n",
       "0  The messages will be \"unwrapped\" by sculptor R...  \n",
       "1  Bloom is to be formally presented with the Han...  \n",
       "2  The classic film It's A Wonderful Life is to b...  \n",
       "3  \"It was very hard to follow last year's extrem...  \n",
       "4  Mary Poppins was originally created by author ...  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example of the article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Article: \n",
      "The classic film It's A Wonderful Life is to be turned into a musical by the producer of the controversial hit show Jerry Springer - The Opera.\n",
      "\n",
      "Frank Capra's 1946 movie starring James Stewart, is being turned into a Â£7m musical by producer Jon Thoday. He is working with Steve Brown, who wrote the award-winning musical Spend Spend Spend. A spokeswoman said the plans were in the \"very early stages\", with no cast, opening date or theatre announced.\n",
      "\n",
      "A series of workshops have been held in London, and on Wednesday a cast of singers unveiled the musical to a select group of potential investors. Mr Thoday said the idea of turning the film into a musical had been an ambition of his for almost 20 years. It's a Wonderful Life was based on a short story, The Greatest Gift, by Philip van Doren Stern. Mr Thoday managed to buy the rights to the story from Van Doren Stern's family in 1999, following Mr Brown's success with Spend Spend Spend. He later secured the film rights from Paramount, enabling them to use the title It's A Wonderful Life.\n"
     ]
    }
   ],
   "source": [
    "def article(article):\n",
    "    \"\"\"\n",
    "    Iterates and prints the articles in the dataset.\n",
    "    Parameter: Article index  \n",
    "    Return: Article\n",
    "    \"\"\"\n",
    "    print(\"Example Article: \")\n",
    "    for i in article:\n",
    "        print(i)\n",
    "article(df['article'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_tokenize(sentence):\n",
    "    \"\"\"\n",
    "    Tokenizes each sentence of the article\n",
    "    Parameter: list of split sentence\n",
    "    Return: Tokenized sentences\n",
    "    \"\"\"\n",
    "    l= []\n",
    "    temp_list = []\n",
    "    for i in range(len(sentence)):\n",
    "        if not (len(temp_list)==0 and sentence[i]==' '):\n",
    "            temp_list.append(sentence[i])\n",
    "        if i==len(sentence)-1 or (sentence[i]=='.' and (not(sentence[i+1].isdigit()) or sentence[i+1]==\" \")):\n",
    "            l.append(''.join(temp_list))\n",
    "            temp_list = []\n",
    "    return l\n",
    "\n",
    "def split_sentence(article):\n",
    "    \"\"\"\n",
    "    Splits the articles into sentences\n",
    "    Parameter: article with index\n",
    "    Return: Tokenized sentences\n",
    "    \"\"\"\n",
    "    sentences = []\n",
    "    for s in article:\n",
    "        sentences.extend(sentence_tokenize(s))  \n",
    "    return sentences\n",
    "\n",
    "def lower_sentence(sentence):\n",
    "    \"\"\"\n",
    "    Converts all the sentences into lowercase\n",
    "    Parameter: Sentences\n",
    "    Return: lowercase sentences\n",
    "    \"\"\"\n",
    "    lower_sentences = [s.lower() for s in sentence]\n",
    "    return lower_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'my',\n",
       " 'we',\n",
       " 'ours',\n",
       " 'you',\n",
       " \"you've\",\n",
       " \"you'd\",\n",
       " 'yours',\n",
       " 'yourselves',\n",
       " 'him']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shows the stop words obtained from NLTK library\n",
    "stop_words[:20:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(sentence):\n",
    "    \"\"\"\n",
    "    Removes stop words from the sentences\n",
    "    Parameter: list of sentences\n",
    "    Return: Sentences with removed stopwords\n",
    "    \"\"\"\n",
    "    new_sentence = \" \".join([i for i in sentence if i not in stop_words])\n",
    "    return new_sentence\n",
    "\n",
    "def clean_sentence(sentences):\n",
    "    \"\"\"\n",
    "    Removes all the special characters from the sentences\n",
    "    Parameter: list of sentences\n",
    "    Return: Sentences with removed special characters\n",
    "    \"\"\"    \n",
    "    s=pd.Series(sentences)\n",
    "    clean_sentences = s.str.replace(\"[^a-zA-Z]\", \" \",regex=True)\n",
    "    return clean_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_embeddings(path):\n",
    "    \"\"\"\n",
    "    Get the word embedding vectors\n",
    "    Parameter: Glove 100d path\n",
    "    Return: word embedding vectors\n",
    "    \"\"\"\n",
    "    word_embeddings = {}\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split() \n",
    "            word = values[0]      \n",
    "            coefs = np.asarray(values[1:], dtype='float32')\n",
    "            word_embeddings[word] = coefs\n",
    "    return word_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word vector size 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.21823 ,  0.69199 ,  0.70441 , -0.59642 , -0.21818 ,  0.55387 ,\n",
       "       -0.32052 ,  0.52602 , -0.31667 , -0.19129 ,  0.76109 ,  0.047439,\n",
       "        0.43199 ,  0.12232 ,  0.25664 , -0.52453 ,  0.048994,  0.81621 ,\n",
       "       -0.53336 ,  0.53093 ,  0.24589 , -0.046352,  0.38898 , -0.41434 ,\n",
       "        0.28169 , -0.35422 ,  0.24713 , -0.44007 ,  0.023343, -0.38592 ,\n",
       "        0.31762 ,  0.26774 , -0.19487 ,  0.024135, -0.056042,  0.33799 ,\n",
       "        0.12103 ,  0.32306 , -0.67209 , -0.028449, -0.79051 , -0.29798 ,\n",
       "        0.25696 , -0.1822  , -0.066176,  0.28468 ,  0.019382, -0.51672 ,\n",
       "       -0.065801, -0.74178 , -0.043   ,  0.10303 , -0.22385 ,  0.96676 ,\n",
       "       -0.38914 , -2.1671  ,  0.25583 ,  0.067169,  2.0256  ,  0.86387 ,\n",
       "       -0.14699 ,  1.0254  , -0.42629 ,  0.19325 ,  0.83025 ,  0.097585,\n",
       "        0.79303 ,  0.4349  ,  0.26404 , -0.17101 , -0.13859 , -0.55096 ,\n",
       "        0.020747, -0.39791 ,  0.43081 ,  0.37966 , -0.52257 , -0.20961 ,\n",
       "       -1.1568  , -0.38041 ,  0.81093 , -0.050365, -0.27241 ,  0.87153 ,\n",
       "       -1.8965  ,  0.19574 , -0.2269  , -0.28267 , -0.14656 , -0.18737 ,\n",
       "       -0.61509 ,  0.009347, -0.3978  ,  0.037638, -1.1974  , -0.26052 ,\n",
       "       -0.72752 , -0.3797  ,  0.68278 ,  0.63878 ], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the word embeddings\n",
    "word= word_embeddings(r\"C:\\Users\\HP PAV -15 AU111TX\\Desktop\\NLP\\Project\\glove.6B\\glove.6B.100d.txt\")\n",
    "print('Word vector size',len(word['all']))\n",
    "word['all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(clean_sentences,word_embeddings,dim):\n",
    "    \"\"\"\n",
    "    Takes the sentences and word embeddings and gives the sentence vector\n",
    "    Parameter: cleaned sentences, word embeddings, dimension of vector \n",
    "    Return: sentence vector\n",
    "    \"\"\"\n",
    "    sentence_vectors = []\n",
    "    for i in clean_sentences:\n",
    "        if len(i) != 0 and len(i.split())!=0:\n",
    "            v = sum([word_embeddings.get(w, np.zeros((dim,))) for w in i.split()])/ (len(i.split()))\n",
    "        else:\n",
    "            v = np.zeros((dim,))\n",
    "        sentence_vectors.append(v)\n",
    "    return sentence_vectors\n",
    "\n",
    "def get_sim_mat(sentences,sentence_vectors,dim):\n",
    "    \"\"\"\n",
    "    Takes the sentences and sentence vectors to create similarity matrix using cosine similarity\n",
    "    Parameter: sentences, sentence vectors, dimension of vector \n",
    "    Return: similarity matrix\n",
    "    \"\"\"\n",
    "    similarity_mat = np.zeros([len(sentences), len(sentences)])\n",
    "    for i in range(len(sentences)):\n",
    "        for j in range(len(sentences)):\n",
    "            if i != j:\n",
    "                similarity_mat[i][j] = cosine_similarity(sentence_vectors[i].reshape(1,dim), sentence_vectors[j].reshape(1,dim))[0,0]\n",
    "    return similarity_mat\n",
    "\n",
    "def rank_sentence(similarity_matrix,sentences):\n",
    "    \"\"\"\n",
    "    Takes the sentences and similarity matrix to rank the sentences using networkx library\n",
    "    Parameter: similarity matrix, sentences\n",
    "    Return: ranked sentences\n",
    "    \"\"\"\n",
    "    nx_graph = nx.from_numpy_array(similarity_matrix)\n",
    "    scores = nx.pagerank(nx_graph)\n",
    "    ranked_sentences = sorted(((scores[i],i) for i,s in enumerate(sentences)), reverse=True)\n",
    "    return ranked_sentences\n",
    "\n",
    "def extract_summary(ranked_sentences, sentence_number):\n",
    "    \"\"\"\n",
    "    Takes the ranked sentences and number of sentences that should be taken from the original summary to extract the new summary\n",
    "    Parameter: ranked sentences, number of sentences that should be considered from the original summary\n",
    "    Return: extracted summary\n",
    "    \"\"\"\n",
    "    result_lst = []\n",
    "    for i in range(sentence_number):\n",
    "        result_lst.append(ranked_sentences[i][1])\n",
    "    return result_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(i,word_embeddings,dim):\n",
    "    \"\"\"\n",
    "    The function tests the extractive summarizartion model by calling all the functions for a particular article and gives the accuracy\n",
    "    Parameter: index of article, word embeddings, dimension of vector\n",
    "    Return: accuracy, old summary, new summary, ranked sentence list\n",
    "    \"\"\"\n",
    "    sentences = split_sentence(df['article'][i])\n",
    "    stop_words = stopwords.words('english')\n",
    "    ls=lower_sentence(sentences)\n",
    "    clean_stopword_sentences = [stopwords_removal(r.split()) for r in ls]\n",
    "    clean_sentences = clean_sentence(clean_stopword_sentences)\n",
    "    sentence_vectors = get_sentence_vector(clean_sentences,word,dim)\n",
    "    similarity_matrix = get_sim_mat(sentences,sentence_vectors,dim)\n",
    "    ranked_sentences = rank_sentence(similarity_matrix,sentences)\n",
    "    data = df['summary'][i]\n",
    "    data = sentence_tokenize(data)\n",
    "    gold = split_sentence(data)\n",
    "    sentence_num = len(gold)\n",
    "    result_lst = extract_summary(ranked_sentences,sentence_num)\n",
    "    result_lst.sort()\n",
    "    gold_lst = []\n",
    "    for i,sent in enumerate(sentences):\n",
    "        if sent in gold:\n",
    "            gold_lst.append(i)\n",
    "    correct = 0\n",
    "    for i in range(len(result_lst)):\n",
    "        if result_lst[i] in gold_lst:\n",
    "            correct+=1\n",
    "    accuracy=correct/sentence_num\n",
    "    return accuracy, data, sentences, result_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 386/386 [01:07<00:00,  5.74it/s, Acc=0.444444]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dim = 100\n",
    "word =word_embeddings(r\"C:\\Users\\HP PAV -15 AU111TX\\Desktop\\NLP\\Project\\glove.6B\\glove.6B.100d.txt\")\n",
    "t=trange(len(df))\n",
    "\n",
    "def result(t,word_embeddings,dim):\n",
    "    \"\"\"\n",
    "    Gives the accuracy of the model \n",
    "    Parameter: length of dataframe, word embeddings and dimesion of vector\n",
    "    Return: None\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    for i in t:\n",
    "        accuracy,data,sentences,result_lst = test(i,word,dim)\n",
    "        result.append(accuracy)\n",
    "        t.set_postfix(Acc='%g' % accuracy)\n",
    "    print(\"Accuracy: \",round(sum(result)/len(result),2))\n",
    "\n",
    "res=result(t,word,dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Summary: \n",
      " Jamie Foxx and Hilary Swank have won the Screen Actors Guild Awards for best male and female film actors, boosting their Oscars hopes this month.Foxx's portrayal of late soul-singer Ray Charles in Ray had already earned him a prestigious Golden Globe award.Modest wine country comedy Sideways knocked out favourites Million Dollar Baby and The Aviator by taking the top prize for best cast performance.Veteran actor Morgan Freeman took the best supporting actor award for playing a prize-fighter turned gym manager in Million Dollar Baby.\"Thank you for Ray Charles for just living so complex and so interesting, and making us all just come together,\" said Foxx, accepting his award in Los Angeles on Saturday.He also praised the film director: \"Thank you for Taylor Hackford for taking a chance with an African-American film.\" Swank, too, was full of praise for her director and co-star Clint Eastwood.Both Foxx and Swank are now considered to be among the favourites to get Oscars - the Hollywood's ultimate prize.\n",
      "\n",
      "Original Summary: \n",
      " Jamie Foxx and Hilary Swank have won the Screen Actors Guild Awards for best male and female film actors, boosting their Oscars hopes this month.Swank triumphed for playing a gutsy female boxer in Million Dollar Baby.Both Foxx and Swank are now considered to be among the favourites to get Oscars - the Hollywood's ultimate prize.Swank, too, was full of praise for her director and co-star Clint Eastwood.Modest wine country comedy Sideways knocked out favourites Million Dollar Baby and The Aviator by taking the top prize for best cast performance.\"I bow down to you,\" Swank said to the 74-year-old Eastwood.Veteran actor Morgan Freeman took the best supporting actor award for playing a prize-fighter turned gym manager in Million Dollar Baby.He also praised the film director: \"Thank you for Taylor Hackford for taking a chance with an African-American film.\n",
      "\n",
      "Article summary: rouge1: 0.83 | rouge2: 0.75 | rougeL: 0.75 \n",
      "Average rouge: 0.8\n"
     ]
    }
   ],
   "source": [
    "def rouge_score(data,sentences,result_lst):\n",
    "    \"\"\"\n",
    "    Gives the rouge score of original summary and extractive summary of any article \n",
    "    Parameter: length of dataframe, word embeddings and dimesion of vector\n",
    "    Return: None\n",
    "    \"\"\"\n",
    "    hypothesis = ''.join([sentences[i] for i in result_lst])\n",
    "    reference = ''.join([ i for i in data])\n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(hypothesis, reference, avg=True)\n",
    "    score_1 = round(scores['rouge-1']['f'], 2)    \n",
    "    score_2 = round(scores['rouge-2']['f'], 2)    \n",
    "    score_L = round(scores['rouge-l']['f'], 2)  \n",
    "    print(\"\\nExtracted Summary: \\n\",hypothesis)\n",
    "    print(\"\\nOriginal Summary: \\n\",reference)\n",
    "    print(\"\\nArticle summary:\" ,\"rouge1:\", score_1, \"| rouge2:\", score_2, \"| rougeL:\",score_2, \"\\nAverage rouge:\",\n",
    "          round(np.mean([score_1,score_2,score_L]), 2))\n",
    "\n",
    "i=50\n",
    "accuracy,data,sentences,result_lst = test(i,word,dim)\n",
    "score=rouge_score(data,sentences,result_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TextRank using Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"gensim==3.8.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.8.1'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gensim.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization import summarize\n",
    "from gensim.summarization import keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A blind student has developed software that turns colours into musical notes so that he can read weather maps.',\n",
       " '',\n",
       " 'Victor Wong, a graduate student from Hong Kong studying at Cornell University in New York State, had to read coloured maps of the upper atmosphere as part of his research. To study \"space weather\" Mr Wong needed to explore minute fluctuations in order to create mathematical models. A number of solutions were tried, including having a colleague describe the maps and attempting to print them in Braille. Mr Wong eventually hit upon the idea of translating individual colours into music, and enlisted the help of a computer graphics specialist and another student to do the programming work.',\n",
       " '',\n",
       " '\"The images have three dimensions and I had to find a way of reading them myself,\" Mr Wong told the BBC News website. \"For the sake of my own study - and for the sake of blind scientists generally - I felt it would be good to develop software that could help us to read colour images.\" He tried a prototype version of the software to explore a photograph of a parrot. In order to have an exact reference to the screen, a pen and tablet device is used. The software then assigns one of 88 piano notes to individually coloured pixels - ranging from blue at the lower end of this scale to red at the upper end. Mr Wong says the application is still very much in its infancy and is only useful for reading images that have been created digitally. \"If I took a random picture and scanned it and then used my software to recognise it, it wouldn\\'t work that well.\"',\n",
       " '',\n",
       " 'Mr Wong has been blind from the age of seven and he thinks that having a \"colour memory\" makes the software more useful than it would be to a scientist who had never had any vision. \"As the notes increase in pitch I know the colour\\'s getting redder and redder, and in my mind\\'s eye a patch of red appears.\" The colour to music software has not yet been made available commercially, and Mr Wong believes that several people would have to work together to make it viable. But he hopes that one day it can be developed to give blind people access to photographs and other images.']"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article'][50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\'Jamie Foxx and Hilary Swank have won the Screen Actors Guild Awards for best male and female film actors, boosting their Oscars hopes this month.\\', \\'\\', \"Foxx\\'s portrayal of late soul-singer Ray Charles in Ray had already earned him a prestigious Golden Globe award.\\nSwank triumphed for playing a gutsy female boxer in Million Dollar Baby.\\nModest wine country comedy Sideways knocked out favourites Million Dollar Baby and The Aviator by taking the top prize for best cast performance.\", \\'\\', \\'The Screen Actors Guild (SAG) represents US film and TV actors.\\nVeteran actor Morgan Freeman took the best supporting actor award for playing a prize-fighter turned gym manager in Million Dollar Baby.\\', \\'\\', \\'\"Thank you for Ray Charles for just living so complex and so interesting, and making us all just come together,\" said Foxx, accepting his award in Los Angeles on Saturday.\\', \\'\\', \\'He also praised the film director: \"Thank you for Taylor Hackford for taking a chance with an African-American film.\\nTaylor, you\\\\\\'re my director of the year.\" Swank, too, was full of praise for her director and co-star Clint Eastwood.\\nIf I\\\\\\'m half the person you are and half the talent you are when I\\\\\\'m 74, I will know that I\\\\\\'ve accomplished something great.\"\\', \\'\\', \"Both Foxx and Swank are now considered to be among the favourites to get Oscars - the Hollywood\\'s ultimate prize.'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def textrank(article, ratio=0.2):\n",
    "    \"\"\"\n",
    "    Summarizes the article with TextRank using Gensim summarizer.  \n",
    "    Parameter: article, ratio or length of summary (ex. 20% of the text)\n",
    "    Return: list of summaries\n",
    "    \"\"\"\n",
    "    article=str(article)\n",
    "    if type(article) is str:     \n",
    "        article = [article]  \n",
    "    list_summaries = [gensim.summarization.summarize(i,ratio=ratio) for i in article]    \n",
    "    return list_summaries\n",
    "i=50\n",
    "summary = textrank(article=df['article'][i], ratio=0.5)    \n",
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_summary(y_test, predicted):  \n",
    "    \n",
    "    rouge = Rouge()\n",
    "    scores = rouge.get_scores(y_test, predicted, avg=True)       \n",
    "    score_1 = round(scores['rouge-1']['f'], 2)    \n",
    "    score_2 = round(scores['rouge-2']['f'], 2)    \n",
    "    score_L = round(scores['rouge-l']['f'], 2)    \n",
    "    print(\"\\nArticle Summary: \", \"rouge1:\", score_1, \"| rouge2:\", score_2, \"| rougeL:\",\n",
    "         score_2, \"\\nAverage rouge:\", round(np.mean([score_1,score_2,score_L]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Article Summary:  rouge1: 0.56 | rouge2: 0.46 | rougeL: 0.46 \n",
      "Average rouge: 0.53\n"
     ]
    }
   ],
   "source": [
    "def summ(i):\n",
    "    \"\"\"\n",
    "    Uses TextRank function to extract the summary from the article\n",
    "    Parameter: index of article\n",
    "    Return: None\n",
    "    \"\"\"\n",
    "    summary = textrank(df['article'][i], ratio=0.2)\n",
    "    s=summary[0]  \n",
    "    punc = '''!()-[]{};:'\"\\,<>/@#$%^&*_~[\"\"'''\n",
    "    for element in s:\n",
    "        if element in punc:\n",
    "            test = s.replace(element, \"\")\n",
    "    return test\n",
    "\n",
    "# index of article\n",
    "i=50\n",
    "s=summ(i)\n",
    "evaluate_summary(df[\"summary\"][i], s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracted Summary\n",
      " Modest wine country comedy Sideways knocked out favourites Million Dollar Baby and The Aviator by taking the top prize for best cast performance.\", '', 'The Screen Actors Guild (SAG) represents US film and TV actors.\n",
      "Veteran actor Morgan Freeman took the best supporting actor award for playing a prizefighter turned gym manager in Million Dollar Baby.', '', '\"Thank you for Ray Charles for just living so complex and so interesting, and making us all just come together,\" said Foxx, accepting his award in Los Angeles on Saturday.', '', 'He also praised the film director: \"Thank you for Taylor Hackford for taking a chance with an AfricanAmerican film.\n",
      "\n",
      "Original Summary\n",
      " Jamie Foxx and Hilary Swank have won the Screen Actors Guild Awards for best male and female film actors, boosting their Oscars hopes this month.Swank triumphed for playing a gutsy female boxer in Million Dollar Baby.Both Foxx and Swank are now considered to be among the favourites to get Oscars - the Hollywood's ultimate prize.Swank, too, was full of praise for her director and co-star Clint Eastwood.Modest wine country comedy Sideways knocked out favourites Million Dollar Baby and The Aviator by taking the top prize for best cast performance.\"I bow down to you,\" Swank said to the 74-year-old Eastwood.Veteran actor Morgan Freeman took the best supporting actor award for playing a prize-fighter turned gym manager in Million Dollar Baby.He also praised the film director: \"Thank you for Taylor Hackford for taking a chance with an African-American film.\n",
      "\n",
      "Article Summary:  rouge1: 0.56 | rouge2: 0.46 | rougeL: 0.46 \n",
      "Average rouge: 0.53\n"
     ]
    }
   ],
   "source": [
    "def printsumm(i):\n",
    "    \"\"\"\n",
    "    Prints the original summary and the predicted summary\n",
    "    Parameter: index of article\n",
    "    Return: None\n",
    "    \"\"\"\n",
    "    predicted_summary= summ(i)\n",
    "    print(\"\\nExtracted Summary\\n\",\"\".join(predicted_summary))\n",
    "    original_summary=df[\"summary\"][i]\n",
    "    print(\"\\nOriginal Summary\\n\",original_summary)\n",
    "    s=summ(i)\n",
    "    evaluate_summary(df[\"summary\"][i], s)\n",
    "    \n",
    "printsumm(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
